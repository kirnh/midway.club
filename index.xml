<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introducing Midway! on Midway</title><link>https://www.midway.club/</link><description>Recent content in Introducing Midway! on Midway</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.midway.club/index.xml" rel="self" type="application/rss+xml"/><item><title>🧠 Real-Time Voice Activity Detection on Raspberry Pi with Silero VAD</title><link>https://www.midway.club/posts/voice-activity-detector/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/voice-activity-detector/</guid><description>&lt;p>In this guide, we implement &lt;strong>real-time voice activity detection (VAD)&lt;/strong> on a Raspberry Pi using the open-source &lt;a href="https://github.com/snakers4/silero-vad">Silero VAD&lt;/a> model. This allows us to listen continuously and trigger further actions &lt;strong>only when human speech is detected&lt;/strong>, even in noisy environments.&lt;/p>
&lt;hr>
&lt;h2 id="-why-real-time-vad-matters">🔥 Why Real-Time VAD Matters&lt;/h2>
&lt;p>When building smart voice systems, it&amp;rsquo;s wasteful (and error-prone) to analyze audio all the time. We want to:&lt;/p>
&lt;ul>
&lt;li>✅ Detect when someone is &lt;strong>actually speaking&lt;/strong>&lt;/li>
&lt;li>❌ Ignore background noise, silence, fans, dogs barking, etc.&lt;/li>
&lt;li>✅ Trigger speaker recognition or transcription &lt;strong>only when voice is present&lt;/strong>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-what-well-use">🛠️ What We’ll Use&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Component&lt;/th>
 &lt;th>Purpose&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>&lt;code>arecord&lt;/code>&lt;/td>
 &lt;td>Efficient audio capture on RPi&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>&lt;code>torchaudio&lt;/code>&lt;/td>
 &lt;td>WAV file loading&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>&lt;code>silero-vad&lt;/code>&lt;/td>
 &lt;td>Tiny PyTorch-based voice detector&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Raspberry Pi&lt;/td>
 &lt;td>Edge device to run everything locally&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-setup">⚙️ Setup&lt;/h2>
&lt;h3 id="install-dependencies">Install Dependencies&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>pip install torchaudio soundfile silero-vad
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo apt install sox alsa-utils
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>✅ Tip: Make sure your microphone shows up in &lt;code>arecord -l&lt;/code>. Use the correct device name (e.g. &lt;code>plughw:1,0&lt;/code>).&lt;/p></description></item><item><title>Real-Time Speaker Recognition on Raspberry Pi Using SpeechBrain</title><link>https://www.midway.club/posts/speechbrain-speaker-recognition/</link><pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/speechbrain-speaker-recognition/</guid><description>&lt;p>This guide demonstrates how to deploy a real-time speaker recognition system on a Raspberry Pi using SpeechBrain&amp;rsquo;s ECAPA-TDNN model. We&amp;rsquo;ll cover model selection, setup, optimization, and deployment for efficient identification.&lt;/p>
&lt;hr>
&lt;h2 id="-why-ecapa-tdnn-over-x-vector">🧠 Why ECAPA-TDNN Over x-vector?&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Feature&lt;/th>
 &lt;th>x-vector&lt;/th>
 &lt;th>ECAPA-TDNN&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>Architecture&lt;/td>
 &lt;td>TDNN&lt;/td>
 &lt;td>SE-Res2Net + TDNN&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Attention Mechanisms&lt;/td>
 &lt;td>❌&lt;/td>
 &lt;td>✅&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Accuracy&lt;/td>
 &lt;td>Moderate&lt;/td>
 &lt;td>High&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Inference Time&lt;/td>
 &lt;td>Faster&lt;/td>
 &lt;td>Slightly Slower&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Recommended for RPi&lt;/td>
 &lt;td>❌&lt;/td>
 &lt;td>✅ (optimized small variant)&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Conclusion&lt;/strong>: ECAPA-TDNN is more robust and suitable even for embedded systems like Raspberry Pi when optimized properly.&lt;/p></description></item><item><title>Streaming Audio from Raspberry Pi to iPad Over Wi-Fi Using GStreamer</title><link>https://www.midway.club/posts/raspberrypi-ipad-audio-wifi/</link><pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/raspberrypi-ipad-audio-wifi/</guid><description>&lt;p>Streaming audio from a Raspberry Pi to an iPad over Wi-Fi allows for a variety of applications, from home intercom systems to real-time monitoring. Since iOS does not support receiving Bluetooth audio directly from external sources, Wi-Fi streaming is the best alternative.&lt;/p>
&lt;p>In this guide, we&amp;rsquo;ll use &lt;strong>GStreamer&lt;/strong>, a powerful multimedia framework, to capture audio from a microphone connected to the Raspberry Pi and stream it over Wi-Fi. The iPad will then receive and play the stream using an app like &lt;strong>VLC for iOS&lt;/strong>.&lt;/p></description></item><item><title>AI-Powered Voice Companions - Market Research</title><link>https://www.midway.club/posts/ai-powered-voice-companions-market-research/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/ai-powered-voice-companions-market-research/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>The way we speak can reveal a lot about our mental and emotional health. Subtle vocal cues – from tone and pitch to pace and pauses – often reflect our mood and stress levels [1]. In recent years, artificial intelligence (AI) has begun leveraging these cues in real time to support mental well-being, improve communication, and even coach our relationships. &lt;strong>AI-driven voice companion&lt;/strong> tools are emerging that listen to &lt;strong>how&lt;/strong> we talk (not just &lt;strong>what&lt;/strong> we say) and provide feedback or support. These range from emotion-sensing mental health apps to AI “communication coaches” that analyze tone in conversations.&lt;/p></description></item><item><title>Enriching Every Conversation</title><link>https://www.midway.club/about/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/about/</guid><description>&lt;h2 id="vision">Vision&lt;/h2>
&lt;p>We envision a future where wearable microphones seamlessly enrich the fabric of daily interactions, fostering deeper understanding, empathy, and emotional connection in personal relationships. Recognizing that strong, nurturing relationships are at the heart of overall mental well-being, we aim to empower individuals to develop healthier communication habits while preserving the privacy and trust essential for genuine human connection.&lt;/p>
&lt;h2 id="mission">Mission&lt;/h2>
&lt;p>Our mission at Midway is to strengthen relationship health through privacy-centric audio solutions. By enabling insightful yet respectful analysis of interpersonal communication patterns, we help individuals and couples cultivate healthier, more fulfilling bonds. We achieve this by:&lt;/p></description></item><item><title>How to Build a Wearable Microphone That Records Only the Speaker for a Full Day</title><link>https://www.midway.club/posts/record-only-speaker/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/record-only-speaker/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>Creating a &lt;strong>wearable microphone&lt;/strong> that records only the speaker while ensuring a full day&amp;rsquo;s battery life requires a combination of &lt;strong>low-power hardware&lt;/strong>, &lt;strong>smart signal processing&lt;/strong>, and &lt;strong>efficient AI models&lt;/strong>. This guide breaks down the key components and steps to achieve this.&lt;/p>
&lt;h2 id="1-hardware-requirements">1. Hardware Requirements&lt;/h2>
&lt;h3 id="microphone-selection">&lt;strong>Microphone Selection&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>MEMS Microphone&lt;/strong> (e.g., Knowles SPH0645LM4H-B) for power efficiency.&lt;/li>
&lt;li>&lt;strong>Directional Microphone&lt;/strong> to focus on the speaker and reduce background noise.&lt;/li>
&lt;li>&lt;strong>Bone Conduction Mic&lt;/strong> (e.g., Vesper VM2020) for extreme noise resistance.&lt;/li>
&lt;/ul>
&lt;h3 id="processing-unit">&lt;strong>Processing Unit&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Low-power DSP (Digital Signal Processor)&lt;/strong> (e.g., Qualcomm QCC5141, Ambiq Apollo4)&lt;/li>
&lt;li>&lt;strong>MCU with Edge AI Support&lt;/strong> (e.g., ESP32-S3, Raspberry Pi RP2040 with TinyML)&lt;/li>
&lt;/ul>
&lt;h3 id="battery--power-optimization">&lt;strong>Battery &amp;amp; Power Optimization&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>1000mAh Li-Po Battery&lt;/strong> for extended life.&lt;/li>
&lt;li>&lt;strong>Efficient Power Management IC (PMIC)&lt;/strong> (e.g., Texas Instruments BQ24074).&lt;/li>
&lt;li>&lt;strong>Low-Power Sleep Mode&lt;/strong> when not in active recording.&lt;/li>
&lt;/ul>
&lt;h2 id="2-ai-based-speaker-recognition">2. AI-Based Speaker Recognition&lt;/h2>
&lt;h3 id="feature-extraction">&lt;strong>Feature Extraction&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>Use &lt;strong>MFCCs (Mel-Frequency Cepstral Coefficients)&lt;/strong> or &lt;strong>wav2vec embeddings&lt;/strong> for voice signatures.&lt;/li>
&lt;/ul>
&lt;h3 id="on-device-speaker-identification">&lt;strong>On-Device Speaker Identification&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Lightweight TinyML Model&lt;/strong> trained on the speaker’s voice.&lt;/li>
&lt;li>&lt;strong>Wake-word detection&lt;/strong> to trigger recording only when the speaker talks.&lt;/li>
&lt;/ul>
&lt;h3 id="noise-filtering">&lt;strong>Noise Filtering&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Beamforming Algorithms&lt;/strong> (e.g., Superdirective Beamforming) to isolate the speaker’s voice.&lt;/li>
&lt;li>&lt;strong>Adaptive Noise Cancellation (ANC)&lt;/strong> using DSP.&lt;/li>
&lt;/ul>
&lt;h2 id="3-storage--data-transmission">3. Storage &amp;amp; Data Transmission&lt;/h2>
&lt;h3 id="storage-options">&lt;strong>Storage Options&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Local Storage (microSD or Flash Memory)&lt;/strong> for offline recording.&lt;/li>
&lt;li>&lt;strong>Compressed Audio (AAC or Opus format)&lt;/strong> for minimal space usage.&lt;/li>
&lt;/ul>
&lt;h3 id="transmission">&lt;strong>Transmission&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Bluetooth Low Energy (BLE)&lt;/strong> for short bursts of audio transmission.&lt;/li>
&lt;li>&lt;strong>Wi-Fi or LTE Module&lt;/strong> (optional) for cloud backup when needed.&lt;/li>
&lt;/ul>
&lt;h2 id="4-wearable-design-considerations">4. Wearable Design Considerations&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Form Factor:&lt;/strong> Necklace, clip-on, or integrated into clothing.&lt;/li>
&lt;li>&lt;strong>Weight:&lt;/strong> Less than 50g for comfort.&lt;/li>
&lt;li>&lt;strong>Heat Dissipation:&lt;/strong> Ensure efficient power use to prevent overheating.&lt;/li>
&lt;/ul>
&lt;h2 id="5-software--model-deployment">5. Software &amp;amp; Model Deployment&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Embedded Firmware:&lt;/strong> TinyML model deployment with TensorFlow Lite.&lt;/li>
&lt;li>&lt;strong>Mobile App:&lt;/strong> Optional app for adjusting settings and reviewing recordings.&lt;/li>
&lt;li>&lt;strong>OTA Updates:&lt;/strong> To improve AI models over time.&lt;/li>
&lt;/ul>
&lt;h2 id="6-expected-battery-life-estimation">6. Expected Battery Life Estimation&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Component&lt;/th>
 &lt;th>Power Consumption&lt;/th>
 &lt;th>Estimated Usage Time&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>MEMS Microphone&lt;/td>
 &lt;td>~0.5mW&lt;/td>
 &lt;td>Negligible impact&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>DSP Processing&lt;/td>
 &lt;td>~10mW&lt;/td>
 &lt;td>~100 hours&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>BLE Transmission&lt;/td>
 &lt;td>~15mW (intermittent)&lt;/td>
 &lt;td>~24+ hours&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Flash Storage Write&lt;/td>
 &lt;td>~20mW&lt;/td>
 &lt;td>~50 hours&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Total Estimated Power Draw&lt;/td>
 &lt;td>~30mW average&lt;/td>
 &lt;td>&lt;strong>24+ hours&lt;/strong>&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h2 id="7-challenges--solutions">7. Challenges &amp;amp; Solutions&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Challenge&lt;/th>
 &lt;th>Solution&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>High background noise&lt;/td>
 &lt;td>Use beamforming + bone conduction mic&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Battery drain&lt;/td>
 &lt;td>Optimize DSP power usage &amp;amp; sleep mode&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Processing on-device&lt;/td>
 &lt;td>Use TinyML with quantized models&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Privacy concerns&lt;/td>
 &lt;td>Store locally, encrypt data&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h2 id="8-next-steps">8. Next Steps&lt;/h2>
&lt;ul>
&lt;li>Prototype with ESP32-S3 + MEMS Mic + BLE.&lt;/li>
&lt;li>Train a TinyML speaker model.&lt;/li>
&lt;li>Optimize power consumption with PMIC.&lt;/li>
&lt;li>Test real-world performance with various noise environments.&lt;/li>
&lt;/ul>
&lt;p>With the right optimizations, this &lt;strong>wearable speaker-specific microphone&lt;/strong> can last a full day while recording only the intended speaker!&lt;/p></description></item><item><title>Privacy in Wearable Technologies - Balancing Always‑On Listening with User Trust</title><link>https://www.midway.club/posts/privacy-in-wearables/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/privacy-in-wearables/</guid><description>&lt;p>Wearable technologies like smartwatches, fitness trackers, smart earbuds, and new AI-powered voice companions offer incredible convenience—but they also spark serious privacy questions. As some devices move toward &lt;strong>constantly listening&lt;/strong> microphones for seamless voice assistance, how can they deliver full functionality &lt;strong>and&lt;/strong> protect user privacy? In this post, we dive into current privacy practices in wearables, the legal landscape, technical privacy solutions, consumer sentiment, and best practices for designing privacy-first voice wearables.&lt;/p></description></item><item><title>Training TinyML Speaker Recognition Model for Deployment on Raspberry Pi</title><link>https://www.midway.club/posts/tinyml-speaker-recognition/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/tinyml-speaker-recognition/</guid><description>&lt;h2 id="introduction">&lt;strong>Introduction&lt;/strong>&lt;/h2>
&lt;p>Speaker recognition on low-power devices is a challenge, but with &lt;strong>TinyML&lt;/strong>, we can build a lightweight model that runs efficiently on a &lt;strong>Raspberry Pi 4&lt;/strong>. Since training requires more computational power, we will use a &lt;strong>Cloud GPU&lt;/strong> to train the model and deploy the optimized version on the Raspberry Pi for real-time inference.&lt;/p>
&lt;hr>
&lt;h2 id="1-audio-preprocessing-feature-extraction">&lt;strong>1. Audio Preprocessing (Feature Extraction)&lt;/strong>&lt;/h2>
&lt;p>To recognize a speaker in real-time, we extract key features from audio. The best method for TinyML is &lt;strong>Mel-Frequency Cepstral Coefficients (MFCCs)&lt;/strong>.&lt;/p></description></item><item><title>Voice Analysis for Mental Well-Being and Communication - A Research-Driven Overview</title><link>https://www.midway.club/posts/voice-analysis-mental-health-reseach-overview/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/voice-analysis-mental-health-reseach-overview/</guid><description>&lt;p>Below is a blog post that focuses on the &lt;strong>research-based findings&lt;/strong> regarding continuous voice monitoring for mental health, communication, and relationship insights. It reflects the core research content—how AI-driven speech analysis works, which metrics it targets, and how these insights align with established psychological frameworks.&lt;/p>
&lt;hr>
&lt;h2 id="1-ai-and-speech-analysis-in-mental-health">1. AI and Speech Analysis in Mental Health&lt;/h2>
&lt;p>&lt;strong>Modern mental health professionals&lt;/strong> are increasingly leveraging AI to analyze speech patterns as indicators of well-being. Subtle changes in how we talk—tone, pitch, pace, and language—often signal shifts in mood or mental state. Below are key research insights:&lt;/p></description></item><item><title>What is Midway?</title><link>https://www.midway.club/posts/what-is-midway/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/what-is-midway/</guid><description>&lt;h1 id="conversations-shape-our-lives-midway-makes-them-better">Conversations Shape Our Lives. Midway Makes Them Better.&lt;/h1>
&lt;hr>
&lt;p>At Midway, we believe that communication is more than just words—it’s the foundation of every meaningful relationship. Whether with a partner, a friend, or a loved one, the quality of our conversations shapes the depth of our connections, our emotional well-being, and even our overall happiness.&lt;/p>
&lt;p>Yet, in today’s world, distractions, misunderstandings, and misaligned expectations often create barriers to true connection. Unspoken feelings lead to distance. Misinterpreted words spark conflict. Busy lives replace deep conversations with surface-level exchanges.&lt;/p></description></item><item><title>Building a Real-Time Audio Visualizer in SwiftUI</title><link>https://www.midway.club/posts/ipad-audio-visualization/</link><pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/ipad-audio-visualization/</guid><description>&lt;p>&lt;em>A step-by-step guide to creating a radial audio visualizer that responds to microphone input&lt;/em>&lt;/p>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In this tutorial, we&amp;rsquo;ll build &amp;ldquo;AudioWave&amp;rdquo; - a SwiftUI app that creates a beautiful radial visualization of audio captured from the device&amp;rsquo;s microphone. This project demonstrates several important iOS development concepts:&lt;/p>
&lt;ul>
&lt;li>Working with microphone permissions and audio recording&lt;/li>
&lt;li>Processing real-time audio data&lt;/li>
&lt;li>Creating custom visualizations with SwiftUI&lt;/li>
&lt;li>Handling iOS permissions properly&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s dive in and see how we can bring audio to life visually!&lt;/p></description></item><item><title>Persistent Bluetooth Connection Between Raspberry Pi and iPad</title><link>https://www.midway.club/posts/raspberrypi-ipad-bluetooth/</link><pubDate>Sat, 15 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/raspberrypi-ipad-bluetooth/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This guide walks you through the process of:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>One-time pairing of the Raspberry Pi with the iPad.&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Setting up a Bash script to maintain a persistent Bluetooth connection.&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Running the script automatically on boot using &lt;code>systemd&lt;/code>.&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>With this setup, the Raspberry Pi will continuously monitor the Bluetooth connection and automatically reconnect to the iPad if disconnected.&lt;/p>
&lt;hr>
&lt;h2 id="1-one-time-bluetooth-pairing">&lt;strong>1. One-Time Bluetooth Pairing&lt;/strong>&lt;/h2>
&lt;p>Before setting up the automatic connection, you need to &lt;strong>pair your iPad with the Raspberry Pi manually&lt;/strong>.&lt;/p></description></item><item><title>Raspberry Pi Headless Setup Guide</title><link>https://www.midway.club/posts/raspberrypi-setup/</link><pubDate>Fri, 14 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/raspberrypi-setup/</guid><description>&lt;h1 id="raspberry-pi-headless-setup-guide">Raspberry Pi Headless Setup Guide&lt;/h1>
&lt;p>Setting up a Raspberry Pi without a monitor, keyboard, or mouse (headless setup) is a convenient way to configure your Pi for remote use. This guide will walk you through the entire process, from flashing the OS to connecting via SSH and setting up Wi-Fi.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;ul>
&lt;li>A Raspberry Pi (any model, preferably with built-in Wi-Fi like the Raspberry Pi 4, 3B+)&lt;/li>
&lt;li>A microSD card (16GB or larger, Class 10 recommended)&lt;/li>
&lt;li>A microSD card reader&lt;/li>
&lt;li>A power adapter suitable for your Raspberry Pi&lt;/li>
&lt;li>A computer (Windows, macOS, or Linux)&lt;/li>
&lt;li>A stable internet connection&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="step-1-download-raspberry-pi-os">Step 1: Download Raspberry Pi OS&lt;/h2>
&lt;p>Raspberry Pi OS (formerly Raspbian) is the recommended operating system. You can download it from the official site:&lt;/p></description></item><item><title>Deploying Hugo site to GitHub Pages</title><link>https://www.midway.club/posts/deploy-hugo-site-to-github-pages/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/deploy-hugo-site-to-github-pages/</guid><description>&lt;p>&lt;strong>🚀 Step 1: Push Your Hugo Site to GitHub&lt;/strong>&lt;/p>
&lt;p>&lt;strong>1.1: Create a GitHub Repository&lt;/strong>&lt;/p>
&lt;p>​	1.	Go to &lt;a href="https://github.com/">GitHub&lt;/a> and create a &lt;strong>new repository&lt;/strong> named midway-club.&lt;/p>
&lt;p>​	2.	&lt;strong>Do not&lt;/strong> add a README, .gitignore, or license (we will handle this manually).&lt;/p>
&lt;p>​	3.	Copy the repository URL (e.g., &lt;a href="https://github.com/yourusername/midway-club.git)">https://github.com/yourusername/midway-club.git)&lt;/a>.&lt;/p>
&lt;p>&lt;strong>1.2: Initialize Git in Your Hugo Project&lt;/strong>&lt;/p>
&lt;pre tabindex="0">&lt;code>git init
git remote add origin https://github.com/yourusername/midway-club.git
git branch -M main
git add .
git commit -m &amp;#34;Initial commit&amp;#34;
git push -u origin main
&lt;/code>&lt;/pre>&lt;p>This pushes your Hugo site to GitHub.&lt;/p></description></item><item><title>Local Hugo Static Website Setup</title><link>https://www.midway.club/posts/local-hugo-static-site-setup/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://www.midway.club/posts/local-hugo-static-site-setup/</guid><description>&lt;p>&lt;strong>Step 1:&lt;/strong>&lt;/p>
&lt;p>&lt;strong>1.1: Install Hugo&lt;/strong>&lt;/p>
&lt;p>Hugo is a static site generator that is simple to use. Install it based on your OS:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>macOS (Homebrew)&lt;/strong>&lt;/p>
&lt;p>&lt;code>brew install hugo&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Windows (Chocolatey)&lt;/strong>&lt;/p>
&lt;p>&lt;code>choco install hugo -confirm&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ubuntu/Debian&lt;/strong>&lt;/p>
&lt;p>&lt;code>sudo apt install hugo&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>1.2: Create Your Site&lt;/strong>&lt;/p>
&lt;p>Run:&lt;/p>
&lt;pre tabindex="0">&lt;code>hugo new site dev-docs
cd dev-docs
&lt;/code>&lt;/pre>&lt;p>&lt;strong>1.3: Choose a Theme&lt;/strong>&lt;/p>
&lt;p>Hugo themes define the design of your site. You can pick one from &lt;a href="https://themes.gohugo.io/">https://themes.gohugo.io/&lt;/a>.&lt;/p>
&lt;p>For a simple, aesthetic theme, let’s use &lt;strong>Paper&lt;/strong>:&lt;/p></description></item></channel></rss>